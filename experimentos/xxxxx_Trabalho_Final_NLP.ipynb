{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJiFwDqtf6eE"
      },
      "source": [
        "# **Case QuantumFinance - Disciplina NLP - Classificador de chamados**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDbi6PDS9MYO"
      },
      "source": [
        "***Participantes (RM - NOME):***<br>\n",
        "xxxx - xxxxx<br>\n",
        "xxxx - xxxxx<br>\n",
        "xxxx - xxxxx<br>\n",
        "xxxx - xxxxx<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xw6WhaNo4k3"
      },
      "source": [
        "### **Crie um classificador de chamados aplicando técnicas de PLN**\n",
        "---\n",
        "\n",
        "A **QuantumFinance** tem um canal de atendimento via chat e precisar classificar os assuntos dos atendimentos para melhorar as tratativas dos chamados dos clientes. O canal recebe textos abertos dos clientes relatando o problema e/ou dúvida e depois é direcionado para alguma área especialista no assunto para uma melhor tratativa.​\n",
        "\n",
        "1. Crie um modelo classificador de assuntos aplicando técnicas de PLN, que consiga classificar através de um texto o assunto conforme disponível na base de dados [1] para treinamento e validação do seu modelo.​\n",
        "\n",
        "  O modelo precisar atingir um score na **métrica F1 Score superior a 75%**. Utilize o dataset [1] para treinar e testar o modelo, separe o dataset em duas amostras (75% para treinamento e 25% para teste com o randon_state igual a 42).​\n",
        "\n",
        "2. Utilizar ao menos uma aplicação de modelos de GenAI (LLM´s) para criar o modelo classificador com os mesmos critérios do item 1.\n",
        "\n",
        "Fique à vontade para testar e explorar as técnicas de pré-processamento, abordagens de NLP, algoritmos e bibliotecas, mas explique e justifique as suas decisões durante o desenvolvimento.​\n",
        "\n",
        "**Composição da nota:​**\n",
        "\n",
        "**50%** - Demonstrações das aplicações das técnicas de PLN (regras, pré-processamentos, tratamentos, variedade de modelos aplicados, aplicações de GenIA, organização do pipeline, etc.)​\n",
        "\n",
        "**50%** - Baseado na performance (score) obtida com a amostra de teste no pipeline do modelo campeão (validar com  a Métrica F1 Score). **Separar o pipeline completo do modelo campeão conforme template.​**\n",
        "\n",
        "O trabalho poderá ser feito em grupo de 2 até 4 pessoas (mesmo grupo do Startup One) e trabalhos iguais serão descontado nota e passível de reprovação.\n",
        "\n",
        "**[1] = ​https://dados-ml-pln.s3.sa-east-1.amazonaws.com/tickets_reclamacoes_classificados.csv**\n",
        "\n",
        "**[F1 Score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)** com average='weighted'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMBI8SQtps1n"
      },
      "outputs": [],
      "source": [
        "# CARREGANDO O DATA FRAME\n",
        "import pandas as pd\n",
        "#df = pd.read_csv('https://dados-ml-pln.s3.sa-east-1.amazonaws.com/tickets_reclamacoes_classificados.csv', delimiter=';')\n",
        "df = pd.read_csv('tickets_reclamacoes_classificados.csv', delimiter=';')\n",
        "\n",
        "# Façam o download do arquivo e utilizem localmente durante os testes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s__lBzDQwrcG",
        "outputId": "e2a77c32-a043-4f90-efa4-806d0f913aba"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyKC9Vhkp0BK"
      },
      "source": [
        "Bom desenvolvimento!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlxCSMk-iAdk"
      },
      "source": [
        "### **Area de desenvolvimento e validações**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2O5PedDdiZLb"
      },
      "source": [
        "Faça aqui as demonstrações das aplicações das técnicas de PLN (regras, pré-processamentos, tratamentos, variedade de modelos aplicados, organização do pipeline, etc.)​\n",
        "\n",
        "Fique à vontade para testar e explorar as técnicas de pré-processamento, abordagens de NLP, algoritmos e bibliotecas, mas explique e justifique as suas decisões durante o desenvolvimento.​"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parte 01 - Uso de ML para Classificação de Textos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Exploração & Pré-processamento dos Textos\n",
        "\n",
        "Além de explorar os dados, aqui aplicamos técnicas clássicas de normalização e limpeza de texto, como:\n",
        "\n",
        "- Lowercasing\n",
        "- Remoção de pontuação, números e padrões via regex (ex: \"xx/xx/xxxx\", \"xxxx\", valores monetários)\n",
        "- Remoção de acentos\n",
        "- Tokenização\n",
        "- Remoção de stopwords (incluindo personalização)\n",
        "- Filtro de palavras curtas\n",
        "\n",
        "O objetivo é preparar os textos para vetorização e modelagem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['categoria'].value_counts()\n",
        "df['categoria'].value_counts(normalize=True) * 100  # Em %\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# verificanr tamanho dos textos \n",
        "\n",
        "df['tamanho_texto'] = df['descricao_reclamacao'].apply(lambda x: len(str(x).split()))\n",
        "df['tamanho_texto'].describe()\n",
        "df_alt = df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# explorando alguns textos por categoria\n",
        "for categoria in df['categoria'].unique():\n",
        "    exemplo = df[df['categoria'] == categoria]['descricao_reclamacao'].iloc[0]\n",
        "    print(f\"\\n >>> Categoria: {categoria}\\nTexto: {exemplo}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Pré-processamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nze8UbKhosm9"
      },
      "outputs": [],
      "source": [
        "!pip install nltk unicode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ue0nV0uVo3OZ"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab') # obtive problemas com o punkt -> essa versao punkt_tab é obsoleta pela documentação\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FziwgqJmw9OD"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import nltk\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Lista de stopwords em português\n",
        "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
        "\n",
        "# Função para remover pontuação\n",
        "def remove_punctuation(text):\n",
        "    punctuations = string.punctuation\n",
        "    table = str.maketrans({key: \" \" for key in punctuations})\n",
        "    text = text.translate(table)\n",
        "    return text\n",
        "\n",
        "# Normalização e tokenização\n",
        "def norm_tokenize(text):\n",
        "    text = str(text).lower()\n",
        "    \n",
        "    # Limpeza com regex \n",
        "    text = re.sub(r'xx+/xx+/xxxx?', ' ', text)  # datas como xx/xx/xxxx\n",
        "    text = re.sub(r'\\$?\\s?\\d+(?:,\\d+)?', ' ', text)  # valores monetários\n",
        "    text = re.sub(r'(?i)\\b[x]{2,}\\b', ' ', text)  # palavras com xxxx, xx etc\n",
        "    text = re.sub(r'\\d+', ' ', text)  # remove números restantes\n",
        "    text = re.sub(r'\\s+', ' ', text)  # espaços duplicados\n",
        "\n",
        "    # Remover pontuação\n",
        "    text = remove_punctuation(text)\n",
        "\n",
        "    # Tokenização\n",
        "    text = word_tokenize(text)\n",
        "\n",
        "    # Remoção de stopwords e palavras curtas\n",
        "    text = [x for x in text if x not in stopwords]\n",
        "    text = [y for y in text if len(y) > 2]\n",
        "\n",
        "    return \" \".join(text)\n",
        "\n",
        "# Aplicando o pré-processamento\n",
        "df_alt['texto_processado'] = df_alt['descricao_reclamacao'].apply(norm_tokenize)\n",
        "\n",
        "# Mostrando antes e depois para alguns exemplos\n",
        "df_alt[['descricao_reclamacao', 'texto_processado']].head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Teste de Vetorizadores e Modelos de Classificação\n",
        "\n",
        "Nesta etapa, comparamos diferentes combinações de vetorizadores e algoritmos de classificação para identificar o pipeline com melhor desempenho.\n",
        "\n",
        "- **TF-IDF (1-2):** Considera unigramas e bigramas com normalização TF-IDF\n",
        "- **TF-IDF (1-3):** Considera unigramas, bigramas e trigramas (mais contexto)\n",
        "- **BoW (1-2):** Modelo tradicional de contagem com unigramas e bigramas\n",
        "\n",
        "Modelos de classificação testados:\n",
        "- **Naive Bayes (MultinomialNB):** \n",
        "- **Logistic Regression:** \n",
        "- **LinearSVC:** \n",
        "- **Random Forest:** \n",
        "\n",
        "Parâmetros:\n",
        "- Todos os vetores foram limitados a **5.000 features** (usando `max_features=5000`)\n",
        "- Dados separados em **75% treino / 25% teste** com `random_state=42` e `stratify=y`\n",
        "- Métrica usada: **F1 Score (weighted)** — ideal para bases com classes desbalanceadas\n",
        "\n",
        "A seguir, apresentamos uma tabela com os resultados ordenados pelo maior F1 Score.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "import pandas as pd\n",
        "\n",
        "X = df_alt['texto_processado']\n",
        "y = df_alt['categoria']\n",
        "\n",
        "vetorizadores = {\n",
        "    'TF-IDF (1-2)': TfidfVectorizer(ngram_range=(1, 2), max_features=5000),\n",
        "    'TF-IDF (1-3)': TfidfVectorizer(ngram_range=(1, 3), max_features=5000),\n",
        "    'BoW (1-2)': CountVectorizer(ngram_range=(1, 2), max_features=5000),\n",
        "}\n",
        "\n",
        "modelos = {\n",
        "    'Naive Bayes': MultinomialNB(),\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "    'LinearSVC': LinearSVC(),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "resultados = []\n",
        "\n",
        "for nome_vet, vet in vetorizadores.items():\n",
        "    X_vet = vet.fit_transform(X)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_vet, y, test_size=0.25, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    for nome_modelo, modelo in modelos.items():\n",
        "        modelo.fit(X_train, y_train)\n",
        "        y_pred = modelo.predict(X_test)\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "        resultados.append({\n",
        "            'Vetorizador': nome_vet,\n",
        "            'Modelo': nome_modelo,\n",
        "            'F1 Score': round(f1, 4)\n",
        "        })\n",
        "\n",
        "# Exibir resultados como DataFrame\n",
        "df_resultados = pd.DataFrame(resultados)\n",
        "print(df_resultados.sort_values(by='F1 Score', ascending=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizar tabela de resutlados\n",
        "df_resultados = pd.DataFrame(resultados).sort_values(by='F1 Score', ascending=False).reset_index(drop=True)\n",
        "\n",
        "# Estilizar a visualização\n",
        "styled = df_resultados.style.set_caption(\"Comparativo de Vetorizadores e Modelos\") \\\n",
        "    .background_gradient(subset=['F1 Score'], cmap='Greens') \\\n",
        "    .format({'F1 Score': '{:.4f}'}) \\\n",
        "    .hide(axis='index') \\\n",
        "    .set_table_styles([{\n",
        "        'selector': 'caption',\n",
        "        'props': [('color', '#333'), ('font-size', '16px'), ('font-weight', 'bold')]\n",
        "    }])\n",
        "\n",
        "styled\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### Nosso modelo campeão escolhido foi Regressão Logísica com 0.90 de F1 utilizando o TF-IDF(1-2) como vetorizador"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parte 2 — Classificação de Texto com GenAI (Embeddings com Transformers)\n",
        "\n",
        "Nesta etapa, vamos aplicar técnicas de PLN com modelos baseados em Transformers para classificar os chamados dos clientes da QuantumFinance.\n",
        "\n",
        "Utilizaremos embeddings gerados com o modelo `paraphrase-multilingual-MiniLM-L12-v2`, que representa frases inteiras como vetores semânticos densos.\n",
        "\n",
        "O pipeline será:\n",
        "\n",
        "1. Carregamento e separação dos dados\n",
        "2. Geração de embeddings com modelo Transformer\n",
        "3. Treinamento de modelo de ML (ex: Logistic Regression)\n",
        "4. Avaliação com F1 Score\n",
        "5. Comparação com o modelo da Parte 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Amostra do dataset:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id_reclamacao</th>\n",
              "      <th>data_abertura</th>\n",
              "      <th>categoria</th>\n",
              "      <th>descricao_reclamacao</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3229299</td>\n",
              "      <td>2019-05-01T12:00:00-05:00</td>\n",
              "      <td>Hipotecas / Empréstimos</td>\n",
              "      <td>Bom dia, meu nome é xxxx xxxx e agradeço se vo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3199379</td>\n",
              "      <td>2019-04-02T12:00:00-05:00</td>\n",
              "      <td>Cartão de crédito / Cartão pré-pago</td>\n",
              "      <td>Atualizei meu cartão xxxx xxxx em xx/xx/2018 e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3233499</td>\n",
              "      <td>2019-05-06T12:00:00-05:00</td>\n",
              "      <td>Cartão de crédito / Cartão pré-pago</td>\n",
              "      <td>O cartão Chase foi relatado em xx/xx/2019. No ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3180294</td>\n",
              "      <td>2019-03-14T12:00:00-05:00</td>\n",
              "      <td>Cartão de crédito / Cartão pré-pago</td>\n",
              "      <td>Em xx/xx/2018, enquanto tentava reservar um ti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3224980</td>\n",
              "      <td>2019-04-27T12:00:00-05:00</td>\n",
              "      <td>Serviços de conta bancária</td>\n",
              "      <td>Meu neto me dê cheque por {$ 1600,00} Eu depos...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id_reclamacao              data_abertura  \\\n",
              "0        3229299  2019-05-01T12:00:00-05:00   \n",
              "1        3199379  2019-04-02T12:00:00-05:00   \n",
              "2        3233499  2019-05-06T12:00:00-05:00   \n",
              "3        3180294  2019-03-14T12:00:00-05:00   \n",
              "4        3224980  2019-04-27T12:00:00-05:00   \n",
              "\n",
              "                             categoria  \\\n",
              "0              Hipotecas / Empréstimos   \n",
              "1  Cartão de crédito / Cartão pré-pago   \n",
              "2  Cartão de crédito / Cartão pré-pago   \n",
              "3  Cartão de crédito / Cartão pré-pago   \n",
              "4           Serviços de conta bancária   \n",
              "\n",
              "                                descricao_reclamacao  \n",
              "0  Bom dia, meu nome é xxxx xxxx e agradeço se vo...  \n",
              "1  Atualizei meu cartão xxxx xxxx em xx/xx/2018 e...  \n",
              "2  O cartão Chase foi relatado em xx/xx/2019. No ...  \n",
              "3  Em xx/xx/2018, enquanto tentava reservar um ti...  \n",
              "4  Meu neto me dê cheque por {$ 1600,00} Eu depos...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Informações do dataset:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 21072 entries, 0 to 21071\n",
            "Data columns (total 4 columns):\n",
            " #   Column                Non-Null Count  Dtype \n",
            "---  ------                --------------  ----- \n",
            " 0   id_reclamacao         21072 non-null  int64 \n",
            " 1   data_abertura         21072 non-null  object\n",
            " 2   categoria             21072 non-null  object\n",
            " 3   descricao_reclamacao  21072 non-null  object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 658.6+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Carregamento dos dados e separação em treino/teste\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Carrega o dataset\n",
        "df = pd.read_csv('tickets_reclamacoes_classificados.csv', sep=';')\n",
        "\n",
        "# Visualiza as primeiras linhas\n",
        "print(\"Amostra do dataset:\")\n",
        "display(df.head())\n",
        "\n",
        "# Verifica colunas e tipos\n",
        "print(\"\\nInformações do dataset:\")\n",
        "print(df.info())\n",
        "\n",
        "# Remove linhas com valores nulos\n",
        "df = df.dropna(subset=['descricao_reclamacao', 'categoria'])\n",
        "\n",
        "# Separação das features (texto) e labels (categorias)\n",
        "X = df['descricao_reclamacao']\n",
        "y = df['categoria']\n",
        "\n",
        "# Split em treino e teste (75/25), como pedido\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=42, stratify=y\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Geração de Embeddings com modelo Transformer\n",
        "\n",
        "Usaremos o modelo `paraphrase-multilingual-MiniLM-L12-v2` da biblioteca `sentence-transformers`.\n",
        "\n",
        "Esse modelo é baseado em BERT e é treinado para gerar **representações semânticas de sentenças** == embeddings. Eificiente para classificacoes e etc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install -U sentence-transformers -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No sentence-transformers model found with name neuralmind/bert-base-portuguese-cased. Creating a new one with mean pooling.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dispositivo em uso: cuda\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1fcebce1c958494caa39710cfdb0fc29",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/494 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4689dff16ee40249a67b9767b486380",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/165 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Verifica se a GPU está disponível\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Dispositivo em uso: {device}\")\n",
        "\n",
        "# Carrega o modelo diretamente na GPU (se disponível)\n",
        "#model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2', device=device)\n",
        "#model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2', device=device)\n",
        "model = SentenceTransformer('neuralmind/bert-base-portuguese-cased', device=device)\n",
        "\n",
        "\n",
        "# Gera os embeddings para os textos de treino e teste\n",
        "X_train_embeddings = model.encode(X_train.tolist(), show_progress_bar=True)\n",
        "X_test_embeddings = model.encode(X_test.tolist(), show_progress_bar=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### Avaliação de Múltiplos Modelos com Embeddings\n",
        "\n",
        "- Agora que já temos os embeddings prontos, vamos testar diversos modelos de machine learning para verificar qual deles apresenta o melhor desempenho na tarefa de classificação.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LogisticRegression   → F1 Score: 80.69%\n",
            "RandomForest         → F1 Score: 64.93%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Lista de modelos para testar\n",
        "modelos = {\n",
        "    'LogisticRegression': LogisticRegression(max_iter=1000),\n",
        "    #'LinearSVC': LinearSVC(),\n",
        "    'RandomForest': RandomForestClassifier()\n",
        "    #'KNN': KNeighborsClassifier(),\n",
        "    #'GaussianNB': GaussianNB()  # pode funcionar mal com vetores densos, mas vamos ver\n",
        "}\n",
        "\n",
        "# Avaliação\n",
        "resultados = []\n",
        "\n",
        "for nome, modelo in modelos.items():\n",
        "    try:\n",
        "        modelo.fit(X_train_embeddings, y_train)\n",
        "        y_pred = modelo.predict(X_test_embeddings)\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "        resultados.append((nome, f1))\n",
        "        print(f'{nome:<20} → F1 Score: {f1:.2%}')\n",
        "    except Exception as e:\n",
        "        print(f'{nome:<20} → Erro: {e}')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Parte 2.2 - Fine tunning completo do BERT \n",
        "\n",
        "Os resultados acima são satisfatórios, mas ainda podemos explorarr algumas coisas:\n",
        "- em vez de usar apenas os embeddings, vamos treinar o modelo BERT completo, incluindo sua camada de saída, diretamente para a tarefa de classificação.\n",
        "- Ajustar os pesos internos de um modelo LLM já pré-treinado, usando um conjunto de dados específico (nossos chamados), para que ele aprenda a resolver melhor a tarefa desejada (classificação de categorias).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\alyss\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Parte 2.2 — Fine-Tuning com BERT (LLM completo)\n",
        "\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "import re, string\n",
        "\n",
        "# Download de recursos do NLTK\n",
        "nltk.download('stopwords')\n",
        "stopwords_list = nltk.corpus.stopwords.words('portuguese')\n",
        "\n",
        "# Lista para substituição de nome de instituições\n",
        "nomes = ['chase', 'bank', 'jp', 'gm', 'financial', 'jpmcb']\n",
        "novo_nome = '[INST]'\n",
        "\n",
        "# Normalização leve, sem remover stopwords que são essenciais para LLMs\n",
        "def remove_punctuation(text):\n",
        "    return text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "def normalize_text(text, replace_institutions=False):\n",
        "    text = re.sub(r'\\d+|/', '', text)\n",
        "    text = re.sub(r'\\bx\\b|\\w*xx+\\w*', '', text)  # remove 'xxx', 'xxxx'\n",
        "    text = remove_punctuation(text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    \n",
        "    if replace_institutions:\n",
        "        for inst in nomes:\n",
        "            text = re.sub(r'\\b' + re.escape(inst) + r'\\b', novo_nome, text) \n",
        "    \n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# >> Tokenizando com BERT \n",
        "# Carrega o tokenizer oficial do BERT em português (cased)\n",
        "tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
        "\n",
        "# Adiciona o token especial usado para nomes de instituições\n",
        "if \"[INST]\" not in tokenizer.get_vocab():\n",
        "    tokenizer.add_tokens([\"[INST]\"])\n",
        "\n",
        "# Função de tokenização completa\n",
        "def bert_tokenize(text):\n",
        "    text = normalize_text(text, replace_institutions=True)\n",
        "    return tokenizer(\n",
        "        text,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=128,\n",
        "        return_tensors='pt'\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenizando os textos com BERT...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21072/21072 [00:52<00:00, 404.74it/s]\n"
          ]
        }
      ],
      "source": [
        "# Preparação dos dados para fine-tuning:\n",
        "# Codificação dos rótulos, tokenização em lote e criação dos tensores\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "# X e y já carregados anteriormente\n",
        "# X = df['descricao_reclamacao']\n",
        "# y = df['categoria'])\n",
        "\n",
        "# Codifica os rótulos (categorias) com números\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# Aplica normalização e tokenização em todos os textos\n",
        "input_ids_list = []\n",
        "attention_masks_list = []\n",
        "\n",
        "print(\"Tokenizando os textos com BERT...\")\n",
        "\n",
        "for texto in tqdm(X):\n",
        "    tokens = bert_tokenize(texto)\n",
        "    input_ids_list.append(tokens['input_ids'].squeeze(0))\n",
        "    attention_masks_list.append(tokens['attention_mask'].squeeze(0))\n",
        "\n",
        "# Converte listas em tensores\n",
        "input_ids_tensor = torch.stack(input_ids_list)\n",
        "attention_mask_tensor = torch.stack(attention_masks_list)\n",
        "labels_tensor = torch.tensor(y_encoded, dtype=torch.long)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Separação em treino e teste + DataLoaders\n",
        "\n",
        "# Divide os dados em treino/teste com base nos tensores\n",
        "train_idx, test_idx = train_test_split(\n",
        "    range(len(X)),\n",
        "    test_size=0.25,\n",
        "    random_state=42,\n",
        "    stratify=y_encoded\n",
        ")\n",
        "\n",
        "# Cria datasets com base nos índices\n",
        "train_dataset = TensorDataset(\n",
        "    input_ids_tensor[train_idx],\n",
        "    attention_mask_tensor[train_idx],\n",
        "    labels_tensor[train_idx]\n",
        ")\n",
        "\n",
        "test_dataset = TensorDataset(\n",
        "    input_ids_tensor[test_idx],\n",
        "    attention_mask_tensor[test_idx],\n",
        "    labels_tensor[test_idx]\n",
        ")\n",
        "\n",
        "# DataLoaders para treinamento e avaliação\n",
        "batch_size = 32\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Agora temos:\n",
        "#train_loader e test_loader com os dados prontos\n",
        "\n",
        "# Tokenização feita com BERT\n",
        "# Labels codificados e vetores de entrada prontos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[  101,  8399,   644,  ...,     0,     0,     0],\n",
              "        [  101, 13103,   535,  ...,     0,     0,     0],\n",
              "        [  101,   231, 12807,  ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [  101,  2542, 12044,  ...,  6176,   202,   102],\n",
              "        [  101,  3396,  4435,  ...,   179,  7343,   102],\n",
              "        [  101,  2511,   125,  ...,  5300,   202,   102]])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_ids_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Usando dispositivo: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
          ]
        }
      ],
      "source": [
        "# Carregar o modelo BERT e configurar o otimizador\n",
        "\n",
        "# Dispositivo: GPU se disponível, senão CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Usando dispositivo: {device}\")\n",
        "\n",
        "# Carrega o modelo pré-treinado BERT para classificação\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'neuralmind/bert-base-portuguese-cased',\n",
        "    num_labels=len(le.classes_)\n",
        ")\n",
        "\n",
        "# Atualiza o vocabulário (caso adicionamos [INST])\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# Move modelo para a GPU (ou CPU)\n",
        "model.to(device)\n",
        "\n",
        "# Define otimizador (AdamW é padrão para transformers)\n",
        "learning_rate = 5e-5\n",
        "#optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando treinamento...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/5: 100%|██████████| 494/494 [02:45<00:00,  2.98it/s, loss=0.621]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss médio da época 1: 0.5992\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/5: 100%|██████████| 494/494 [02:45<00:00,  2.99it/s, loss=0.423] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss médio da época 2: 0.3927\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/5: 100%|██████████| 494/494 [02:45<00:00,  2.99it/s, loss=0.531] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss médio da época 3: 0.2727\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/5: 100%|██████████| 494/494 [02:46<00:00,  2.96it/s, loss=0.0235]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss médio da época 4: 0.1665\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/5: 100%|██████████| 494/494 [02:45<00:00,  2.98it/s, loss=0.132]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss médio da época 5: 0.1114\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Loop de treinamento (Fine-Tuning)\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Parâmetros do treinamento\n",
        "num_epochs =  5  # (Loss médio da época 5: 0.0832)\n",
        "model.train()\n",
        "\n",
        "print(\"Iniciando treinamento...\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "    for batch in loop:\n",
        "        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = output.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    print(f\"Loss médio da época {epoch+1}: {total_loss / len(train_loader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relatório de Classificação:\n",
            "                                     precision    recall  f1-score   support\n",
            "\n",
            "Cartão de crédito / Cartão pré-pago       0.72      0.92      0.81      1252\n",
            "            Hipotecas / Empréstimos       0.80      0.87      0.83       962\n",
            "                             Outros       0.76      0.64      0.70       558\n",
            "       Roubo / Relatório de disputa       0.81      0.77      0.79      1206\n",
            "         Serviços de conta bancária       0.92      0.73      0.81      1290\n",
            "\n",
            "                           accuracy                           0.80      5268\n",
            "                          macro avg       0.80      0.79      0.79      5268\n",
            "                       weighted avg       0.81      0.80      0.80      5268\n",
            "\n",
            "[X] F1 Score Final: 79.80%\n"
          ]
        }
      ],
      "source": [
        "model.eval()  # coloca o modelo em modo de avaliação\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():  # não precisamos calcular gradientes aqui\n",
        "    for batch in test_loader:\n",
        "        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        predictions = torch.argmax(logits, dim=1)\n",
        "\n",
        "        all_preds.extend(predictions.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Decodifica os rótulos numéricos de volta para texto\n",
        "y_pred = le.inverse_transform(all_preds)\n",
        "y_true = le.inverse_transform(all_labels)\n",
        "\n",
        "# Avaliação\n",
        "print(\"Relatório de Classificação:\")\n",
        "print(classification_report(y_true, y_pred))\n",
        "\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "print(f\"[X] F1 Score Final: {f1:.2%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68SiMjcWqD_m"
      },
      "source": [
        "### **Validação do professor**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T24EasckqG2I"
      },
      "source": [
        "Consolidar apenas os scripts do seu **modelo campeão**, desde o carregamento do dataframe, separação das amostras, tratamentos utilizados (funções, limpezas, etc.), criação dos objetos de vetorização dos textos e modelo treinado e outras implementações utilizadas no processo de desenvolvimento do modelo.\n",
        "\n",
        "O modelo precisar atingir um score na métrica F1 Score superior a 75%.\n",
        "\n",
        "**Atenção:** **Implemente aqui apenas os scripts que fazem parte do modelo campeão.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "BuJtvcfXo3J4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\alyss\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\alyss\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "´ [ x ] F1 Score do modelo campeão (TF-IDF + Regressão Logística): 0.9047\n"
          ]
        }
      ],
      "source": [
        "# PIPILINE FINAL: TF-IDF (1-2) + Regressão Logística\n",
        "\n",
        "# Imports\n",
        "import pandas as pd\n",
        "import string\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Setup NLTK\n",
        "nltk.download('punkt')\n",
        "#nltk.download('punkt_tab') # descomentar em caso de problemas \n",
        "nltk.download('stopwords')\n",
        "\n",
        "# dataset\n",
        "#df = pd.read_csv('https://dados-ml-pln.s3.sa-east-1.amazonaws.com/tickets_reclamacoes_classificados.csv', delimiter=';') \n",
        "df = pd.read_csv('tickets_reclamacoes_classificados.csv', sep=';')\n",
        "\n",
        "# Funções de pré-processamento\n",
        "stopwords = set(stopwords.words('portuguese'))\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    table = str.maketrans({key: \" \" for key in string.punctuation})\n",
        "    return text.translate(table)\n",
        "\n",
        "def norm_tokenize(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'xx+/xx+/xxxx?', ' ', text)\n",
        "    text = re.sub(r'\\$?\\s?\\d+(?:,\\d+)?', ' ', text)\n",
        "    text = re.sub(r'(?i)\\b[x]{2,}\\b', ' ', text)\n",
        "    text = re.sub(r'\\d+', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = remove_punctuation(text)\n",
        "    tokens = text.split()\n",
        "    tokens = [t for t in tokens if t not in stopwords and len(t) > 2]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Aplicando pré-processamento\n",
        "df['texto_processado'] = df['descricao_reclamacao'].apply(norm_tokenize)\n",
        "\n",
        "# Separação dos dados\n",
        "X = df['texto_processado']\n",
        "y = df['categoria']\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Vetorização com TF-IDF (1-2)\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=5000)\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Modelo campeão: Regressão Logística\n",
        "modelo = LogisticRegression(max_iter=1000)\n",
        "modelo.fit(X_train_vec, y_train)\n",
        "\n",
        "# Avaliação com F1 Score\n",
        "y_pred = modelo.predict(X_test_vec)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "print(f'´ [ x ] F1 Score do modelo campeão (TF-IDF + Regressão Logística): {f1:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Conclusão Final**\n",
        "\n",
        "Parte 1 — Abordagem tradicional de PLN + ML\n",
        "-Aplicamos técnicas clássicas de pré-processamento, tokenização e vetorização (TF-IDF com N-gramas);\n",
        "-Utilizamos vários modelos de machine learning para testar e aprender sobre o comportamento;\n",
        "-Essa abordagem obteve um F1 Score superior a `80%`, tornando-se o melhor desempenho geral\n",
        "\n",
        "Parte 2 — Abordagem com GenAI (LLM com Transformers)\n",
        "-Utilizamos o modelo paraphrase-multilingual-MiniLM-L12-v2 para gerar embeddings semânticos com sentence-transformers.\n",
        "-Também testamos o modelo mais robusto paraphrase-multilingual-mpnet-base-v2, aproveitando aceleração via GPU.\n",
        "-Foram avaliados diversos classificadores (Logistic Regression, SVC, Random Forest, etc.).\n",
        "-O melhor F1 Score foi de ~77.98% com LinearSVC + MiniLM, e ~76.96% com mpnet.\n",
        "\n",
        "Dessa forma, \n",
        "apesar do uso de modelos modernos baseados em LLM, o modelo tradicional da Parte 1 obteve desempenho superior em F1 Score. \n",
        "Isso mostra que:\n",
        " - Em problemas com vocabulário controlado e estrutura previsível, abordagens clássicas ainda podem ser mais eficientes.\n",
        " - Modelos baseados em Transformers são promissores, especialmente com fine-tuning específico, mas exigem mais recursos e ajustes.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
