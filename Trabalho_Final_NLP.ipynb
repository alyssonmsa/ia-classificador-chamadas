{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJiFwDqtf6eE"
      },
      "source": [
        "# **Case QuantumFinance - Disciplina NLP - Classificador de chamados**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDbi6PDS9MYO"
      },
      "source": [
        "***Participantes (RM - NOME):***<br>\n",
        "355729 - ALYSSON MARQUEZELLI S ALMEIDA<br>\n",
        "356520 - NATANAEL DE OLIVEIRA CASTRO<br>\n",
        "355741 - VICTOR FERNANDES CARDOSO<br>\n",
        "356427 - MATEUS DA ROS SCHUMACHER<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xw6WhaNo4k3"
      },
      "source": [
        "### **Crie um classificador de chamados aplicando técnicas de PLN**\n",
        "---\n",
        "\n",
        "A **QuantumFinance** tem um canal de atendimento via chat e precisar classificar os assuntos dos atendimentos para melhorar as tratativas dos chamados dos clientes. O canal recebe textos abertos dos clientes relatando o problema e/ou dúvida e depois é direcionado para alguma área especialista no assunto para uma melhor tratativa.​\n",
        "\n",
        "1. Crie um modelo classificador de assuntos aplicando técnicas de PLN, que consiga classificar através de um texto o assunto conforme disponível na base de dados [1] para treinamento e validação do seu modelo.​\n",
        "\n",
        "  O modelo precisar atingir um score na **métrica F1 Score superior a 75%**. Utilize o dataset [1] para treinar e testar o modelo, separe o dataset em duas amostras (75% para treinamento e 25% para teste com o randon_state igual a 42).​\n",
        "\n",
        "2. Utilizar ao menos uma aplicação de modelos de GenAI (LLM´s) para criar o modelo classificador com os mesmos critérios do item 1.\n",
        "\n",
        "Fique à vontade para testar e explorar as técnicas de pré-processamento, abordagens de NLP, algoritmos e bibliotecas, mas explique e justifique as suas decisões durante o desenvolvimento.​\n",
        "\n",
        "**Composição da nota:​**\n",
        "\n",
        "**50%** - Demonstrações das aplicações das técnicas de PLN (regras, pré-processamentos, tratamentos, variedade de modelos aplicados, aplicações de GenIA, organização do pipeline, etc.)​\n",
        "\n",
        "**50%** - Baseado na performance (score) obtida com a amostra de teste no pipeline do modelo campeão (validar com  a Métrica F1 Score). **Separar o pipeline completo do modelo campeão conforme template.​**\n",
        "\n",
        "O trabalho poderá ser feito em grupo de 2 até 4 pessoas (mesmo grupo do Startup One) e trabalhos iguais serão descontado nota e passível de reprovação.\n",
        "\n",
        "**[1] = ​https://dados-ml-pln.s3.sa-east-1.amazonaws.com/tickets_reclamacoes_classificados.csv**\n",
        "\n",
        "**[F1 Score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)** com average='weighted'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DMBI8SQtps1n"
      },
      "outputs": [],
      "source": [
        "# CARREGANDO O DATA FRAME\n",
        "import pandas as pd\n",
        "#df = pd.read_csv('https://dados-ml-pln.s3.sa-east-1.amazonaws.com/tickets_reclamacoes_classificados.csv', delimiter=';')\n",
        "df = pd.read_csv('tickets_reclamacoes_classificados.csv', delimiter=';')\n",
        "\n",
        "# Façam o download do arquivo e utilizem localmente durante os testes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s__lBzDQwrcG",
        "outputId": "e2a77c32-a043-4f90-efa4-806d0f913aba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 21072 entries, 0 to 21071\n",
            "Data columns (total 4 columns):\n",
            " #   Column                Non-Null Count  Dtype \n",
            "---  ------                --------------  ----- \n",
            " 0   id_reclamacao         21072 non-null  int64 \n",
            " 1   data_abertura         21072 non-null  object\n",
            " 2   categoria             21072 non-null  object\n",
            " 3   descricao_reclamacao  21072 non-null  object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 658.6+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyKC9Vhkp0BK"
      },
      "source": [
        "Bom desenvolvimento!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlxCSMk-iAdk"
      },
      "source": [
        "### **Area de desenvolvimento e validações**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2O5PedDdiZLb"
      },
      "source": [
        "Faça aqui as demonstrações das aplicações das técnicas de PLN (regras, pré-processamentos, tratamentos, variedade de modelos aplicados, organização do pipeline, etc.)​\n",
        "\n",
        "Fique à vontade para testar e explorar as técnicas de pré-processamento, abordagens de NLP, algoritmos e bibliotecas, mas explique e justifique as suas decisões durante o desenvolvimento.​"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Parte 01 - Uso de ML para Classificação de Textos**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Exploração & Pré-processamento dos Textos\n",
        "\n",
        "Além de explorar os dados, aqui aplicamos técnicas clássicas de normalização e limpeza de texto, como:\n",
        "\n",
        "- Lowercasing\n",
        "- Remoção de pontuação, números e padrões via regex (ex: \"xx/xx/xxxx\", \"xxxx\", valores monetários)\n",
        "- Remoção de acentos\n",
        "- Tokenização\n",
        "- Remoção de stopwords (incluindo personalização)\n",
        "- Filtro de palavras curtas\n",
        "\n",
        "O objetivo é preparar os textos para vetorização e modelagem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "id_reclamacao           0\n",
              "data_abertura           0\n",
              "categoria               0\n",
              "descricao_reclamacao    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "categoria\n",
              "Serviços de conta bancária             24.492217\n",
              "Cartão de crédito / Cartão pré-pago    23.756644\n",
              "Roubo / Relatório de disputa           22.883447\n",
              "Hipotecas / Empréstimos                18.270691\n",
              "Outros                                 10.597001\n",
              "Name: proportion, dtype: float64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['categoria'].value_counts()\n",
        "df['categoria'].value_counts(normalize=True) * 100  # Em %\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# verificanr tamanho dos textos \n",
        "\n",
        "df['tamanho_texto'] = df['descricao_reclamacao'].apply(lambda x: len(str(x).split()))\n",
        "df['tamanho_texto'].describe()\n",
        "df_alt = df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " >>> Categoria: Hipotecas / Empréstimos\n",
            "Texto: Bom dia, meu nome é xxxx xxxx e agradeço se você puder me ajudar a acabar com os serviços de membro do cartão bancário.\n",
            "Em 2018, escrevi para Chase solicitar verificação da dívida e o que eles me enviaram uma declaração que não é aceitável. Estou pedindo ao banco que valide a dívida. Em vez disso, recebi e -mails todos os meses, tentando coletar uma dívida.\n",
            "Tenho o direito de conhecer essas informações como consumidor.\n",
            "\n",
            "Conta do Chase # xxxx xxxx xxxx xxxx Obrigado antecipadamente pela sua ajuda.\n",
            "\n",
            " >>> Categoria: Cartão de crédito / Cartão pré-pago\n",
            "Texto: Atualizei meu cartão xxxx xxxx em xx/xx/2018 e fui informado pelo agente que fez a atualização que minha data de aniversário não mudaria. Ele virou o agente me dando as informações erradas para atualizar a conta. Xxxx alterou minha data de aniversário de xx/xx/xxxx para xx/xx/xxxx sem meu consentimento! XXXX tem a gravação do agente que me enganou.\n",
            "\n",
            " >>> Categoria: Serviços de conta bancária\n",
            "Texto: Meu neto me dê cheque por {$ 1600,00} Eu depositei -o na minha conta Chase depois que o fundo limpo meu banco de perseguição fechou minha conta nunca me pagou meu dinheiro, eles disseram que precisavam para espreitar com o cheque do meu neto estava claro que o dinheiro estava fazendo pela minha perseguição Banco se recusa a me pagar meu dinheiro, meu neto chamou Chase 2 vezes, eles disseram que eu deveria ligar para ele para verificar o proprietário do cheque, ele está fora do país a maior parte da data de horário acontecer xx/xx/2018 Número de cheque xxxx Número de reclamação é xxxx com correr atrás\n",
            "\n",
            " >>> Categoria: Outros\n",
            "Texto: Durante os meses de verão, experimento uma renda de declínio devido ao meu emprego. Portanto, solicito uma extensão de pagamento de um mês com minha empresa de empréstimos para automóveis, Chase. Nos últimos quase quatro anos, meu pedido de extensão de pagamento é concedido. Nunca fui delinqüente com meu pagamento de empréstimo automático. No entanto, em XX/XX/2019, meu pedido de uma extensão de pagamento de um mês foi negada este ano. Expliquei minha situação ao representante e ao supervisor sem sucesso. Após uma longa discussão e espera, fui informado o motivo do declínio, pois não é \"contratual\". Esse motivo de negação me confundi e, portanto, enviei um e -mail ao Escritório da XXXX XXXX Diretor Executivo, Comunicação, JPMorgan Chase & Co. O representante entrou em contato comigo e afirmou que Chase seguirá. Cerca de semana depois, um representante do escritório xxxx xxxx xxxx chamado. O representante compartilhou seu papel foi ajudar a resolver o assunto. O representante via teleconferência contatou o departamento entregando meu pedido. Após, revisando Minhas informações minha solicitação ainda foi negado com base em \"mudanças de política\". Solicitei uma explicação e o representante declarou que uma carta será enviada por correio com explicação. Recebi o XXXX LETTERS O motivo da negação não foi \"mudanças de política\". Gostaria que a ajuda do CFPB para explorar a negação da minha solicitação de extensão de pagamento, especialmente porque fui claro motivo de negação.\n",
            "\n",
            " >>> Categoria: Roubo / Relatório de disputa\n",
            "Texto: Em xxxx xx/xx/2019, fiz um pagamento {$ 300.00} a um varejista on -line usando o Chase Quick Pay com xxxx no site da Chase. Percebi que este era um site de fraudes após nenhuma confirmação, produto ou resposta a quaisquer perguntas sobre o pedido e contatou o Chase para obter mais informações sobre a transação para tentar obter um reembolso pelo banco de varejistas.\n",
            "\n",
            "Entrei em contato com o Chase por meio de uma mensagem segura em xx/xx/2019 explicando o que aconteceu e perguntei: \"Existe uma maneira de reverter essa transação, ou você tem um contato no XXXX que pode me fornecer mais informações sobre o destinatário? '' Que xxxx , minha mensagem foi revisada e recebi uma resposta reafirmando meu e -mail original e me informando que \"a transferência foi concluída. No entanto, como você mencionou que o site é uma farsa enquanto podemos lidar com a maioria das perguntas por e -mail, algumas exigem a experiência de outra equipe. Para ajudá -lo melhor em relação ao reembolso, solicitamos que você ligue para nossa equipe de suporte técnico on -line do consumidor. '' Liguei para o número listado no e -mail e expliquei minha situação para ser transferida para o departamento de reivindicações. Fui instruído a ligar para xxxx e perguntar sobre a transação porque o Chase não tinha nenhuma informação fora do que eu forneci ao iniciar a transferência. Eu senti que esse agente estava tentando me encerrar a ligação o mais rápido possível e tive que interromper o script de fechamento dela para pedir um número de contato no XXXX e não tive a oportunidade de obter nenhuma informação sobre quais perguntas certas Seria perguntar ao xxxx ou que palavras e frases eu deveria usar para obter as informações que estava procurando.\n",
            "\n",
            "Liguei para o XXXX, que é o sistema automatizado inicialmente me instruiu a ligar para o meu banco porque usei o aplicativo Banks para iniciar a transação. Liguei para o XXXX novamente para navegar em seus menus e conversar com um agente de atendimento ao cliente. Eles me disseram que todas as informações sobre a transação faria no sistema da Chase porque usei o aplicativo Banks para executar a transação. Ela ficou na fila comigo até que eu entendesse tudo o que eu deveria perguntar e tive uma melhor compreensão da situação. Terminei a chamada e liguei para Chase novamente.\n",
            "\n",
            "Quando liguei para Chase pela segunda vez, o agente tentou procurar as informações sobre o banco receptor, mas não conseguiu encontrar nenhuma informação adicional. Ela então me perguntou por que eu precisava dessas informações e expliquei minha situação novamente. Mais uma vez, fui transferido para o departamento de reivindicações, que me disse que precisava entrar em contato com o XXXX para obter as informações que estava procurando. Depois que eu disse a ela que eu já havia contatado, ela finalmente admitiu que não havia nada que ela pudesse fazer devido à natureza da transação e que esses tipos de transações não estão garantidos. Ela disse que Chase não tinha informações sobre o destinatário além do endereço de e -mail que eu inseri e que as informações bancárias dos destinatários não foram mantidas no sistema. Em ambos os telefonemas, eles perguntaram se eu iniciou essa transação e o usou para se absolver de toda a responsabilidade em relação a esse assunto.\n",
            "\n",
            "Durante todo esse processo, parecia que Chase não era transparente sobre suas políticas sobre esses tipos de transações, nem foram úteis para me ajudar a obter informações sobre a situação. Essas transações são anunciadas como uma maneira \"rápida, segura e fácil de enviar dinheiro\", mas parece ser uma maneira perigosa de fazer negócios. Sinto -me enganado pela publicidade de Chase e ainda mais vitimada pela maneira como fui tratado pelos membros em sua equipe de atendimento ao cliente.\n"
          ]
        }
      ],
      "source": [
        "# explorando alguns textos por categoria\n",
        "for categoria in df['categoria'].unique():\n",
        "    exemplo = df[df['categoria'] == categoria]['descricao_reclamacao'].iloc[0]\n",
        "    print(f\"\\n >>> Categoria: {categoria}\\nTexto: {exemplo}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Pré-processamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nze8UbKhosm9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (3.9.1)\n",
            "Requirement already satisfied: unicode in c:\\users\\alyss\\appdata\\roaming\\python\\python312\\site-packages (2.9)\n",
            "Requirement already satisfied: click in c:\\users\\alyss\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk unicode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ue0nV0uVo3OZ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     C:\\Users\\alyss\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\alyss\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab') # obtive problemas com o punkt -> essa versao punkt_tab é obsoleta pela documentação\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FziwgqJmw9OD"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>descricao_reclamacao</th>\n",
              "      <th>texto_processado</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bom dia, meu nome é xxxx xxxx e agradeço se vo...</td>\n",
              "      <td>bom dia nome agradeço puder ajudar acabar serv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Atualizei meu cartão xxxx xxxx em xx/xx/2018 e...</td>\n",
              "      <td>atualizei cartão informado agente fez atualiza...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>O cartão Chase foi relatado em xx/xx/2019. No ...</td>\n",
              "      <td>cartão chase relatado entanto pedido fraudulen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Em xx/xx/2018, enquanto tentava reservar um ti...</td>\n",
              "      <td>enquanto tentava reservar ticket deparei ofert...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Meu neto me dê cheque por {$ 1600,00} Eu depos...</td>\n",
              "      <td>neto cheque depositei conta chase fundo limpo ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                descricao_reclamacao  \\\n",
              "0  Bom dia, meu nome é xxxx xxxx e agradeço se vo...   \n",
              "1  Atualizei meu cartão xxxx xxxx em xx/xx/2018 e...   \n",
              "2  O cartão Chase foi relatado em xx/xx/2019. No ...   \n",
              "3  Em xx/xx/2018, enquanto tentava reservar um ti...   \n",
              "4  Meu neto me dê cheque por {$ 1600,00} Eu depos...   \n",
              "\n",
              "                                    texto_processado  \n",
              "0  bom dia nome agradeço puder ajudar acabar serv...  \n",
              "1  atualizei cartão informado agente fez atualiza...  \n",
              "2  cartão chase relatado entanto pedido fraudulen...  \n",
              "3  enquanto tentava reservar ticket deparei ofert...  \n",
              "4  neto cheque depositei conta chase fundo limpo ...  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import string\n",
        "import nltk\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Lista de stopwords em português\n",
        "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
        "\n",
        "# Função para remover pontuação\n",
        "def remove_punctuation(text):\n",
        "    punctuations = string.punctuation\n",
        "    table = str.maketrans({key: \" \" for key in punctuations})\n",
        "    text = text.translate(table)\n",
        "    return text\n",
        "\n",
        "# Normalização e tokenização\n",
        "def norm_tokenize(text):\n",
        "    text = str(text).lower()\n",
        "    \n",
        "    # Limpeza com regex \n",
        "    text = re.sub(r'xx+/xx+/xxxx?', ' ', text)  # datas como xx/xx/xxxx\n",
        "    text = re.sub(r'\\$?\\s?\\d+(?:,\\d+)?', ' ', text)  # valores monetários\n",
        "    text = re.sub(r'(?i)\\b[x]{2,}\\b', ' ', text)  # palavras com xxxx, xx etc\n",
        "    text = re.sub(r'\\d+', ' ', text)  # remove números restantes\n",
        "    text = re.sub(r'\\s+', ' ', text)  # espaços duplicados\n",
        "\n",
        "    # Remover pontuação\n",
        "    text = remove_punctuation(text)\n",
        "\n",
        "    # Tokenização\n",
        "    text = word_tokenize(text)\n",
        "\n",
        "    # Remoção de stopwords e palavras curtas\n",
        "    text = [x for x in text if x not in stopwords]\n",
        "    text = [y for y in text if len(y) > 2]\n",
        "\n",
        "    return \" \".join(text)\n",
        "\n",
        "# Aplicando o pré-processamento\n",
        "df_alt['texto_processado'] = df_alt['descricao_reclamacao'].apply(norm_tokenize)\n",
        "\n",
        "# Mostrando antes e depois para alguns exemplos\n",
        "df_alt[['descricao_reclamacao', 'texto_processado']].head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Teste de Vetorizadores e Modelos de Classificação\n",
        "\n",
        "Nesta etapa, comparamos diferentes combinações de vetorizadores e algoritmos de classificação para identificar o pipeline com melhor desempenho.\n",
        "\n",
        "- **TF-IDF (1-2):** Considera unigramas e bigramas com normalização TF-IDF\n",
        "- **TF-IDF (1-3):** Considera unigramas, bigramas e trigramas (mais contexto)\n",
        "- **BoW (1-2):** Modelo tradicional de contagem com unigramas e bigramas\n",
        "\n",
        "Modelos de classificação testados:\n",
        "- **Naive Bayes (MultinomialNB):** \n",
        "- **Logistic Regression:** \n",
        "- **LinearSVC:** \n",
        "- **Random Forest:** \n",
        "\n",
        "Parâmetros:\n",
        "- Todos os vetores foram limitados a **5.000 features** (usando `max_features=5000`)\n",
        "- Dados separados em **75% treino / 25% teste** com `random_state=42` e `stratify=y`\n",
        "- Métrica usada: **F1 Score (weighted)** — ideal para bases com classes desbalanceadas\n",
        "\n",
        "A seguir, apresentamos uma tabela com os resultados ordenados pelo maior F1 Score.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\alyss\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     Vetorizador               Modelo  F1 Score\n",
            "1   TF-IDF (1-2)  Logistic Regression    0.9059\n",
            "5   TF-IDF (1-3)  Logistic Regression    0.9045\n",
            "9      BoW (1-2)  Logistic Regression    0.9031\n",
            "6   TF-IDF (1-3)            LinearSVC    0.8986\n",
            "2   TF-IDF (1-2)            LinearSVC    0.8971\n",
            "10     BoW (1-2)            LinearSVC    0.8817\n",
            "7   TF-IDF (1-3)        Random Forest    0.8503\n",
            "3   TF-IDF (1-2)        Random Forest    0.8491\n",
            "11     BoW (1-2)        Random Forest    0.8385\n",
            "8      BoW (1-2)          Naive Bayes    0.8250\n",
            "0   TF-IDF (1-2)          Naive Bayes    0.8087\n",
            "4   TF-IDF (1-3)          Naive Bayes    0.8073\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "import pandas as pd\n",
        "\n",
        "X = df_alt['texto_processado']\n",
        "y = df_alt['categoria']\n",
        "\n",
        "vetorizadores = {\n",
        "    'TF-IDF (1-2)': TfidfVectorizer(ngram_range=(1, 2), max_features=5000),\n",
        "    'TF-IDF (1-3)': TfidfVectorizer(ngram_range=(1, 3), max_features=5000),\n",
        "    'BoW (1-2)': CountVectorizer(ngram_range=(1, 2), max_features=5000),\n",
        "}\n",
        "\n",
        "modelos = {\n",
        "    'Naive Bayes': MultinomialNB(),\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "    'LinearSVC': LinearSVC(),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "resultados = []\n",
        "\n",
        "for nome_vet, vet in vetorizadores.items():\n",
        "    X_vet = vet.fit_transform(X)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_vet, y, test_size=0.25, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    for nome_modelo, modelo in modelos.items():\n",
        "        modelo.fit(X_train, y_train)\n",
        "        y_pred = modelo.predict(X_test)\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "        resultados.append({\n",
        "            'Vetorizador': nome_vet,\n",
        "            'Modelo': nome_modelo,\n",
        "            'F1 Score': round(f1, 4)\n",
        "        })\n",
        "\n",
        "# Exibir resultados como DataFrame\n",
        "df_resultados = pd.DataFrame(resultados)\n",
        "print(df_resultados.sort_values(by='F1 Score', ascending=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_b6445 caption {\n",
              "  color: #333;\n",
              "  font-size: 16px;\n",
              "  font-weight: bold;\n",
              "}\n",
              "#T_b6445_row0_col2 {\n",
              "  background-color: #00441b;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_b6445_row1_col2 {\n",
              "  background-color: #00481d;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_b6445_row2_col2 {\n",
              "  background-color: #004d1f;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_b6445_row3_col2 {\n",
              "  background-color: #005b25;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_b6445_row4_col2 {\n",
              "  background-color: #006027;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_b6445_row5_col2 {\n",
              "  background-color: #218944;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_b6445_row6_col2 {\n",
              "  background-color: #8bcf89;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_b6445_row7_col2 {\n",
              "  background-color: #90d18d;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_b6445_row8_col2 {\n",
              "  background-color: #b2e0ac;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_b6445_row9_col2 {\n",
              "  background-color: #d9f0d3;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_b6445_row10_col2 {\n",
              "  background-color: #f5fbf3;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_b6445_row11_col2 {\n",
              "  background-color: #f7fcf5;\n",
              "  color: #000000;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_b6445\">\n",
              "  <caption>Comparativo de Vetorizadores e Modelos</caption>\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th id=\"T_b6445_level0_col0\" class=\"col_heading level0 col0\" >Vetorizador</th>\n",
              "      <th id=\"T_b6445_level0_col1\" class=\"col_heading level0 col1\" >Modelo</th>\n",
              "      <th id=\"T_b6445_level0_col2\" class=\"col_heading level0 col2\" >F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_b6445_row0_col0\" class=\"data row0 col0\" >TF-IDF (1-2)</td>\n",
              "      <td id=\"T_b6445_row0_col1\" class=\"data row0 col1\" >Logistic Regression</td>\n",
              "      <td id=\"T_b6445_row0_col2\" class=\"data row0 col2\" >0.9059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_b6445_row1_col0\" class=\"data row1 col0\" >TF-IDF (1-3)</td>\n",
              "      <td id=\"T_b6445_row1_col1\" class=\"data row1 col1\" >Logistic Regression</td>\n",
              "      <td id=\"T_b6445_row1_col2\" class=\"data row1 col2\" >0.9045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_b6445_row2_col0\" class=\"data row2 col0\" >BoW (1-2)</td>\n",
              "      <td id=\"T_b6445_row2_col1\" class=\"data row2 col1\" >Logistic Regression</td>\n",
              "      <td id=\"T_b6445_row2_col2\" class=\"data row2 col2\" >0.9031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_b6445_row3_col0\" class=\"data row3 col0\" >TF-IDF (1-3)</td>\n",
              "      <td id=\"T_b6445_row3_col1\" class=\"data row3 col1\" >LinearSVC</td>\n",
              "      <td id=\"T_b6445_row3_col2\" class=\"data row3 col2\" >0.8986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_b6445_row4_col0\" class=\"data row4 col0\" >TF-IDF (1-2)</td>\n",
              "      <td id=\"T_b6445_row4_col1\" class=\"data row4 col1\" >LinearSVC</td>\n",
              "      <td id=\"T_b6445_row4_col2\" class=\"data row4 col2\" >0.8971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_b6445_row5_col0\" class=\"data row5 col0\" >BoW (1-2)</td>\n",
              "      <td id=\"T_b6445_row5_col1\" class=\"data row5 col1\" >LinearSVC</td>\n",
              "      <td id=\"T_b6445_row5_col2\" class=\"data row5 col2\" >0.8817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_b6445_row6_col0\" class=\"data row6 col0\" >TF-IDF (1-3)</td>\n",
              "      <td id=\"T_b6445_row6_col1\" class=\"data row6 col1\" >Random Forest</td>\n",
              "      <td id=\"T_b6445_row6_col2\" class=\"data row6 col2\" >0.8503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_b6445_row7_col0\" class=\"data row7 col0\" >TF-IDF (1-2)</td>\n",
              "      <td id=\"T_b6445_row7_col1\" class=\"data row7 col1\" >Random Forest</td>\n",
              "      <td id=\"T_b6445_row7_col2\" class=\"data row7 col2\" >0.8491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_b6445_row8_col0\" class=\"data row8 col0\" >BoW (1-2)</td>\n",
              "      <td id=\"T_b6445_row8_col1\" class=\"data row8 col1\" >Random Forest</td>\n",
              "      <td id=\"T_b6445_row8_col2\" class=\"data row8 col2\" >0.8385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_b6445_row9_col0\" class=\"data row9 col0\" >BoW (1-2)</td>\n",
              "      <td id=\"T_b6445_row9_col1\" class=\"data row9 col1\" >Naive Bayes</td>\n",
              "      <td id=\"T_b6445_row9_col2\" class=\"data row9 col2\" >0.8250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_b6445_row10_col0\" class=\"data row10 col0\" >TF-IDF (1-2)</td>\n",
              "      <td id=\"T_b6445_row10_col1\" class=\"data row10 col1\" >Naive Bayes</td>\n",
              "      <td id=\"T_b6445_row10_col2\" class=\"data row10 col2\" >0.8087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_b6445_row11_col0\" class=\"data row11 col0\" >TF-IDF (1-3)</td>\n",
              "      <td id=\"T_b6445_row11_col1\" class=\"data row11 col1\" >Naive Bayes</td>\n",
              "      <td id=\"T_b6445_row11_col2\" class=\"data row11 col2\" >0.8073</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x1e0a5bb7740>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Visualizar tabela de resutlados\n",
        "df_resultados = pd.DataFrame(resultados).sort_values(by='F1 Score', ascending=False).reset_index(drop=True)\n",
        "\n",
        "# Estilizar a visualização\n",
        "styled = df_resultados.style.set_caption(\"Comparativo de Vetorizadores e Modelos\") \\\n",
        "    .background_gradient(subset=['F1 Score'], cmap='Greens') \\\n",
        "    .format({'F1 Score': '{:.4f}'}) \\\n",
        "    .hide(axis='index') \\\n",
        "    .set_table_styles([{\n",
        "        'selector': 'caption',\n",
        "        'props': [('color', '#333'), ('font-size', '16px'), ('font-weight', 'bold')]\n",
        "    }])\n",
        "\n",
        "styled\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### Nosso modelo campeão escolhido foi Regressão Logísica com 0.90 de F1 utilizando o TF-IDF(1-2) como vetorizador"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Parte 2 — Classificação de Texto com GenAI (Embeddings com Transformers)**\n",
        "\n",
        "Nesta etapa, vamos aplicar técnicas de PLN com modelos baseados em Transformers para classificar os chamados dos clientes da QuantumFinance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.1 Setup Inicial\n",
        "\n",
        "```python\n",
        "# Etapa 1 de 10\n",
        "# Importa bibliotecas essenciais e define o dispositivo (GPU ou CPU) \n",
        "\n",
        "## Parte 2: Modelagem com LLM (BERT)\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\alyss\\AppData\\Local\\Temp\\ipykernel_19744\\2241865917.py:3: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
            "  get_ipython().magic('reset -sf')\n"
          ]
        }
      ],
      "source": [
        "# Limpa todas as variáveis do notebook para tentar algum isolamento\n",
        "from IPython import get_ipython\n",
        "get_ipython().magic('reset -sf')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from sklearn import preprocessing\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executando em: cuda\n"
          ]
        }
      ],
      "source": [
        "def set_seed(seed=42): #tive problemas com random_state\n",
        "    import random\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# Verifica o dispositivo\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Executando em:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parâmetros ajustáveis para facilitar tuning posterior\n",
        "\n",
        "MAX_LENGTH = 256       # Tamanho máximo de tokens por entrada\n",
        "BATCH_SIZE = 32        # Tamanho do batch para treino\n",
        "LEARNING_RATE = 5e-5   # Taxa de aprendizado\n",
        "EPOCHS = 5             # Número de épocas de treinamento\n",
        "DEV_MODE = False       # Usa apenas uma amostra do dataset para acelerar testes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2. Carregamento dos Dados\n",
        "\n",
        "```python\n",
        "# Etapa 2 de 10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Amostra dos dados:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id_reclamacao</th>\n",
              "      <th>data_abertura</th>\n",
              "      <th>categoria</th>\n",
              "      <th>descricao_reclamacao</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3229299</td>\n",
              "      <td>2019-05-01T12:00:00-05:00</td>\n",
              "      <td>Hipotecas / Empréstimos</td>\n",
              "      <td>Bom dia, meu nome é xxxx xxxx e agradeço se vo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3199379</td>\n",
              "      <td>2019-04-02T12:00:00-05:00</td>\n",
              "      <td>Cartão de crédito / Cartão pré-pago</td>\n",
              "      <td>Atualizei meu cartão xxxx xxxx em xx/xx/2018 e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3233499</td>\n",
              "      <td>2019-05-06T12:00:00-05:00</td>\n",
              "      <td>Cartão de crédito / Cartão pré-pago</td>\n",
              "      <td>O cartão Chase foi relatado em xx/xx/2019. No ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3180294</td>\n",
              "      <td>2019-03-14T12:00:00-05:00</td>\n",
              "      <td>Cartão de crédito / Cartão pré-pago</td>\n",
              "      <td>Em xx/xx/2018, enquanto tentava reservar um ti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3224980</td>\n",
              "      <td>2019-04-27T12:00:00-05:00</td>\n",
              "      <td>Serviços de conta bancária</td>\n",
              "      <td>Meu neto me dê cheque por {$ 1600,00} Eu depos...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id_reclamacao              data_abertura  \\\n",
              "0        3229299  2019-05-01T12:00:00-05:00   \n",
              "1        3199379  2019-04-02T12:00:00-05:00   \n",
              "2        3233499  2019-05-06T12:00:00-05:00   \n",
              "3        3180294  2019-03-14T12:00:00-05:00   \n",
              "4        3224980  2019-04-27T12:00:00-05:00   \n",
              "\n",
              "                             categoria  \\\n",
              "0              Hipotecas / Empréstimos   \n",
              "1  Cartão de crédito / Cartão pré-pago   \n",
              "2  Cartão de crédito / Cartão pré-pago   \n",
              "3  Cartão de crédito / Cartão pré-pago   \n",
              "4           Serviços de conta bancária   \n",
              "\n",
              "                                descricao_reclamacao  \n",
              "0  Bom dia, meu nome é xxxx xxxx e agradeço se vo...  \n",
              "1  Atualizei meu cartão xxxx xxxx em xx/xx/2018 e...  \n",
              "2  O cartão Chase foi relatado em xx/xx/2019. No ...  \n",
              "3  Em xx/xx/2018, enquanto tentava reservar um ti...  \n",
              "4  Meu neto me dê cheque por {$ 1600,00} Eu depos...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colunas disponíveis: ['id_reclamacao', 'data_abertura', 'categoria', 'descricao_reclamacao']\n",
            "\n",
            "Distribuição das categorias:\n",
            "categoria\n",
            "Serviços de conta bancária             5161\n",
            "Cartão de crédito / Cartão pré-pago    5006\n",
            "Roubo / Relatório de disputa           4822\n",
            "Hipotecas / Empréstimos                3850\n",
            "Outros                                 2233\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "caminho_arquivo = 'tickets_reclamacoes_classificados.csv'\n",
        "df = pd.read_csv(caminho_arquivo, sep=';')\n",
        "\n",
        "# Ativa modo de desenvolvimento com amostragem reduzida\n",
        "if DEV_MODE:\n",
        "    df = df.sample(frac=0.1, random_state=42).reset_index(drop=True)\n",
        "    print(f\"[MODO DEV ATIVADO] Usando {len(df)} amostras\")\n",
        "\n",
        "print(\"Amostra dos dados:\")\n",
        "display(df.head())\n",
        "\n",
        "print(\"Colunas disponíveis:\", df.columns.tolist())\n",
        "print(\"\\nDistribuição das categorias:\")\n",
        "print(df['categoria'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Etapa 3 de 10\n",
        "- Normaliza os textos "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pré-visualização das colunas originais e normalizadas:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>descricao_reclamacao</th>\n",
              "      <th>texto_limpo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bom dia, meu nome é xxxx xxxx e agradeço se vo...</td>\n",
              "      <td>bom dia meu nome é e agradeço se você puder me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Atualizei meu cartão xxxx xxxx em xx/xx/2018 e...</td>\n",
              "      <td>atualizei meu cartão em e fui informado pelo a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>O cartão Chase foi relatado em xx/xx/2019. No ...</td>\n",
              "      <td>o cartão [INST] foi relatado em no entanto o p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Em xx/xx/2018, enquanto tentava reservar um ti...</td>\n",
              "      <td>em enquanto tentava reservar um ticket me depa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Meu neto me dê cheque por {$ 1600,00} Eu depos...</td>\n",
              "      <td>meu neto me dê cheque por eu depositei o na mi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                descricao_reclamacao  \\\n",
              "0  Bom dia, meu nome é xxxx xxxx e agradeço se vo...   \n",
              "1  Atualizei meu cartão xxxx xxxx em xx/xx/2018 e...   \n",
              "2  O cartão Chase foi relatado em xx/xx/2019. No ...   \n",
              "3  Em xx/xx/2018, enquanto tentava reservar um ti...   \n",
              "4  Meu neto me dê cheque por {$ 1600,00} Eu depos...   \n",
              "\n",
              "                                         texto_limpo  \n",
              "0  bom dia meu nome é e agradeço se você puder me...  \n",
              "1  atualizei meu cartão em e fui informado pelo a...  \n",
              "2  o cartão [INST] foi relatado em no entanto o p...  \n",
              "3  em enquanto tentava reservar um ticket me depa...  \n",
              "4  meu neto me dê cheque por eu depositei o na mi...  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "institution_names = ['chase', 'bank', 'jp', 'gm', 'financial', 'jpmcb']\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    return text.translate(table)\n",
        "\n",
        "def normalize_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\d+|/', '', text)\n",
        "    text = re.sub(r'\\bx\\b|\\w*xx+\\w*', '', text)\n",
        "    text = remove_punctuation(text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    for institution in institution_names:\n",
        "        text = re.sub(r'\\b' + re.escape(institution) + r'\\b', '[INST]', text)\n",
        "\n",
        "    return text\n",
        "\n",
        "# Cria nova coluna com texto normalizado\n",
        "df['texto_limpo'] = df['descricao_reclamacao'].apply(normalize_text)\n",
        "\n",
        "# Visualiza resultado\n",
        "print(\"Pré-visualização das colunas originais e normalizadas:\")\n",
        "df[['descricao_reclamacao', 'texto_limpo']].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4. Tokenização com BERT\n",
        "```python\n",
        "# Etapa 4 de 10\n",
        "# Tokeniza os textos normalizados usando BERT e armazena input_ids e attention_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pré-visualização dos textos tokenizados:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto_limpo</th>\n",
              "      <th>input_ids</th>\n",
              "      <th>attention_mask</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bom dia meu nome é e agradeço se você puder me...</td>\n",
              "      <td>[101, 4062, 644, 7343, 655, 253, 122, 13406, 5...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>atualizei meu cartão em e fui informado pelo a...</td>\n",
              "      <td>[101, 2233, 15134, 22283, 7343, 12807, 173, 12...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>o cartão [INST] foi relatado em no entanto o p...</td>\n",
              "      <td>[101, 146, 12807, 164, 13760, 11846, 166, 262,...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>em enquanto tentava reservar um ticket me depa...</td>\n",
              "      <td>[101, 173, 1139, 17366, 6105, 22282, 222, 964,...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>meu neto me dê cheque por eu depositei o na mi...</td>\n",
              "      <td>[101, 7343, 10588, 311, 121, 22325, 765, 455, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         texto_limpo  \\\n",
              "0  bom dia meu nome é e agradeço se você puder me...   \n",
              "1  atualizei meu cartão em e fui informado pelo a...   \n",
              "2  o cartão [INST] foi relatado em no entanto o p...   \n",
              "3  em enquanto tentava reservar um ticket me depa...   \n",
              "4  meu neto me dê cheque por eu depositei o na mi...   \n",
              "\n",
              "                                           input_ids  \\\n",
              "0  [101, 4062, 644, 7343, 655, 253, 122, 13406, 5...   \n",
              "1  [101, 2233, 15134, 22283, 7343, 12807, 173, 12...   \n",
              "2  [101, 146, 12807, 164, 13760, 11846, 166, 262,...   \n",
              "3  [101, 173, 1139, 17366, 6105, 22282, 222, 964,...   \n",
              "4  [101, 7343, 10588, 311, 121, 22325, 765, 455, ...   \n",
              "\n",
              "                                      attention_mask  \n",
              "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
        "\n",
        "# Tokenização e vetorização dos textos normalizados\n",
        "def tokenize_bert(text):\n",
        "    tokens = tokenizer(\n",
        "        text,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=MAX_LENGTH,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    return tokens\n",
        "\n",
        "# Aplica tokenização e extrai os tensores como listas\n",
        "encoded = df['texto_limpo'].apply(tokenize_bert)\n",
        "df['input_ids'] = encoded.apply(lambda x: x['input_ids'].squeeze().tolist())\n",
        "df['attention_mask'] = encoded.apply(lambda x: x['attention_mask'].squeeze().tolist())\n",
        "\n",
        "# Visualiza colunas com embeddings\n",
        "print(\"Pré-visualização dos textos tokenizados:\")\n",
        "df[['texto_limpo', 'input_ids', 'attention_mask']].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 5. Rótulos\n",
        "\n",
        "```python\n",
        "# Etapa 5 de 10\n",
        "# Codifica os rótulos da coluna 'categoria' em valores numéricos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Categorias codificadas:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>categoria</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cartão de crédito / Cartão pré-pago</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hipotecas / Empréstimos</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Outros</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Roubo / Relatório de disputa</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Serviços de conta bancária</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             categoria  label\n",
              "0  Cartão de crédito / Cartão pré-pago      0\n",
              "1              Hipotecas / Empréstimos      1\n",
              "2                               Outros      2\n",
              "3         Roubo / Relatório de disputa      3\n",
              "4           Serviços de conta bancária      4"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "label_encoder = preprocessing.LabelEncoder()\n",
        "df['label'] = label_encoder.fit_transform(df['categoria'])\n",
        "\n",
        "# Visualiza a correspondência\n",
        "print(\"Categorias codificadas:\")\n",
        "display(pd.DataFrame({\n",
        "    'categoria': label_encoder.classes_,\n",
        "    'label': list(range(len(label_encoder.classes_)))\n",
        "}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 6. Tensores e Split Treino/Teste\n",
        "\n",
        "```python\n",
        "# Etapa 6 de 10\n",
        "# Cria os tensores (input_ids, attention_mask, label) e divide os dados (75/25 com random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tamanho do treino: 15804\n",
            "Tamanho do teste: 5268\n"
          ]
        }
      ],
      "source": [
        "# Converte listas para tensores\n",
        "input_ids_tensor = torch.tensor(df['input_ids'].tolist())\n",
        "attention_mask_tensor = torch.tensor(df['attention_mask'].tolist())\n",
        "labels_tensor = torch.tensor(df['label'].tolist())\n",
        "\n",
        "# Realiza o split dos índices para manter os dados organizados\n",
        "train_idx, test_idx = train_test_split(\n",
        "    range(len(df)),\n",
        "    test_size=0.25,\n",
        "    random_state=42,\n",
        "    stratify=df['label']  # garante distribuição proporcional\n",
        ")\n",
        "\n",
        "# Cria conjuntos de treino e teste\n",
        "train_dataset = TensorDataset(\n",
        "    input_ids_tensor[train_idx],\n",
        "    attention_mask_tensor[train_idx],\n",
        "    labels_tensor[train_idx]\n",
        ")\n",
        "\n",
        "test_dataset = TensorDataset(\n",
        "    input_ids_tensor[test_idx],\n",
        "    attention_mask_tensor[test_idx],\n",
        "    labels_tensor[test_idx]\n",
        ")\n",
        "\n",
        "print(f\"Tamanho do treino: {len(train_dataset)}\")\n",
        "print(f\"Tamanho do teste: {len(test_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 7. Construção e Treinamento do Modelo BERT\n",
        "\n",
        "```python\n",
        "# Etapa 7 de 10\n",
        "# Instancia o modelo BERT para classificação e realiza o treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Época 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 494/494 [05:17<00:00,  1.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss final da época 1: 0.2078\n",
            "\n",
            "Época 2/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 494/494 [05:16<00:00,  1.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss final da época 2: 0.3271\n",
            "\n",
            "Época 3/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 494/494 [05:16<00:00,  1.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss final da época 3: 0.3362\n",
            "\n",
            "Época 4/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 494/494 [05:16<00:00,  1.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss final da época 4: 0.1204\n",
            "\n",
            "Época 5/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 494/494 [05:16<00:00,  1.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss final da época 5: 0.0700\n"
          ]
        }
      ],
      "source": [
        "num_labels = len(label_encoder.classes_)\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'neuralmind/bert-base-portuguese-cased',\n",
        "    num_labels=num_labels\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "# Otimizador e parâmetros\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "batch_size = BATCH_SIZE\n",
        "epochs = EPOCHS\n",
        "\n",
        "# Loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Treinamento\n",
        "model.train()\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nÉpoca {epoch + 1}/{epochs}\")\n",
        "    for batch in tqdm(train_loader):\n",
        "        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "        loss = outputs.loss\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Loss final da época {epoch + 1}: {loss.item():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 8. Avaliação do Modelo\n",
        "\n",
        "```python\n",
        "# Etapa 8 de 10\n",
        "# Avalia o modelo no conjunto de teste usando F1 Score e classification report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                     precision    recall  f1-score   support\n",
            "\n",
            "Cartão de crédito / Cartão pré-pago       0.85      0.90      0.88      1252\n",
            "            Hipotecas / Empréstimos       0.88      0.90      0.89       962\n",
            "                             Outros       0.74      0.84      0.78       558\n",
            "       Roubo / Relatório de disputa       0.91      0.79      0.84      1206\n",
            "         Serviços de conta bancária       0.89      0.89      0.89      1290\n",
            "\n",
            "                           accuracy                           0.87      5268\n",
            "                          macro avg       0.86      0.86      0.86      5268\n",
            "                       weighted avg       0.87      0.87      0.87      5268\n",
            "\n",
            "F1 Score (macro): 0.8580\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, f1_score\n",
        "\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in DataLoader(test_dataset, batch_size=BATCH_SIZE):\n",
        "        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        preds = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Relatório de classificação\n",
        "print(classification_report(all_labels, all_preds, target_names=label_encoder.classes_))\n",
        "\n",
        "# F1 Score Macro\n",
        "f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "print(f\"F1 Score (macro): {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 9. Salvamento do Modelo\n",
        "\n",
        "```python\n",
        "# Etapa 9 de 10\n",
        "# Salva o modelo treinado, o tokenizer e o codificador de rótulos (label encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo, tokenizer e label encoder salvos em 'modelo_quantumfinance/'\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "# Cria pasta se não existir\n",
        "import os\n",
        "os.makedirs(\"modelo_quantumfinance\", exist_ok=True)\n",
        "\n",
        "# Salva modelo e tokenizer\n",
        "model.save_pretrained(\"modelo_quantumfinance\")\n",
        "tokenizer.save_pretrained(\"modelo_quantumfinance\")\n",
        "\n",
        "# Salva o label encoder\n",
        "joblib.dump(label_encoder, \"modelo_quantumfinance/label_encoder.pkl\")\n",
        "\n",
        "print(\"Modelo, tokenizer e label encoder salvos em 'modelo_quantumfinance/'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 10. Predição com Novos Textos \n",
        "\n",
        "```python\n",
        "# Etapa 10 de 10\n",
        "# Usa o modelo treinado para prever a categoria de um novo texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prever_texto(texto):\n",
        "    texto_limpo = normalize_text(texto)\n",
        "    tokens = tokenizer(texto_limpo, return_tensors='pt', truncation=True, padding='max_length', max_length=MAX_LENGTH)\n",
        "    tokens = {k: v.to(device) for k, v in tokens.items()}\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        output = model(**tokens)\n",
        "        pred = torch.argmax(output.logits, dim=1).cpu().item()\n",
        "\n",
        "    return label_encoder.inverse_transform([pred])[0]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "caso_cartao_1: Roubo / Relatório de disputa\n",
            "caso_cartao_2: Cartão de crédito / Cartão pré-pago\n",
            "caso_emprestimo: Hipotecas / Empréstimos\n",
            "caso_hipoteca: Hipotecas / Empréstimos\n",
            "caso_conta: Serviços de conta bancária\n",
            "caso_roubo_1: Roubo / Relatório de disputa\n",
            "caso_roubo_2: Roubo / Relatório de disputa\n",
            "caso_outros_1: Hipotecas / Empréstimos\n",
            "caso_outros_2: Roubo / Relatório de disputa\n"
          ]
        }
      ],
      "source": [
        "casos_teste = {\n",
        "    \"caso_cartao_1\": \"Recebi uma cobrança indevida no meu cartão de crédito e não consigo cancelar.\",\n",
        "    \"caso_cartao_2\": \"Preciso desbloquear meu cartão pré-pago que foi bloqueado sem explicação.\",\n",
        "    \"caso_emprestimo\": \"Estou com problemas para renegociar meu empréstimo estudantil.\",\n",
        "    \"caso_hipoteca\": \"O banco está me cobrando taxas abusivas na minha hipoteca.\",\n",
        "    \"caso_conta\": \"Minha conta foi encerrada sem aviso e perdi o acesso ao meu saldo.\",\n",
        "    \"caso_roubo_1\": \"Alguém fez compras no meu nome, quero reportar uma fraude.\",\n",
        "    \"caso_roubo_2\": \"Tem transações estranhas no meu extrato, acho que fui vítima de golpe.\",\n",
        "    \"caso_outros_1\": \"Quero atualizar meu endereço de correspondência.\",\n",
        "    \"caso_outros_2\": \"Estou tentando mudar minha senha, mas o sistema não deixa.\",\n",
        "}\n",
        "\n",
        "for nome, texto in casos_teste.items():\n",
        "    categoria = prever_texto(texto)\n",
        "    print(f\"{nome}: {categoria}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68SiMjcWqD_m"
      },
      "source": [
        "### **Validação do professor**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T24EasckqG2I"
      },
      "source": [
        "Consolidar apenas os scripts do seu **modelo campeão**, desde o carregamento do dataframe, separação das amostras, tratamentos utilizados (funções, limpezas, etc.), criação dos objetos de vetorização dos textos e modelo treinado e outras implementações utilizadas no processo de desenvolvimento do modelo.\n",
        "\n",
        "O modelo precisar atingir um score na métrica F1 Score superior a 75%.\n",
        "\n",
        "**Atenção:** **Implemente aqui apenas os scripts que fazem parte do modelo campeão.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "BuJtvcfXo3J4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\alyss\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\alyss\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "´ [ x ] F1 Score do modelo campeão (TF-IDF + Regressão Logística): 0.9047\n"
          ]
        }
      ],
      "source": [
        "# PIPILINE FINAL: TF-IDF (1-2) + Regressão Logística\n",
        "\n",
        "# Imports\n",
        "import pandas as pd\n",
        "import string\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Setup NLTK\n",
        "nltk.download('punkt')\n",
        "#nltk.download('punkt_tab') # descomentar em caso de problemas \n",
        "nltk.download('stopwords')\n",
        "\n",
        "# dataset\n",
        "#df = pd.read_csv('https://dados-ml-pln.s3.sa-east-1.amazonaws.com/tickets_reclamacoes_classificados.csv', delimiter=';') \n",
        "df = pd.read_csv('tickets_reclamacoes_classificados.csv', sep=';')\n",
        "\n",
        "# Funções de pré-processamento\n",
        "stopwords = set(stopwords.words('portuguese'))\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    table = str.maketrans({key: \" \" for key in string.punctuation})\n",
        "    return text.translate(table)\n",
        "\n",
        "def norm_tokenize(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'xx+/xx+/xxxx?', ' ', text)\n",
        "    text = re.sub(r'\\$?\\s?\\d+(?:,\\d+)?', ' ', text)\n",
        "    text = re.sub(r'(?i)\\b[x]{2,}\\b', ' ', text)\n",
        "    text = re.sub(r'\\d+', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = remove_punctuation(text)\n",
        "    tokens = text.split()\n",
        "    tokens = [t for t in tokens if t not in stopwords and len(t) > 2]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Aplicando pré-processamento\n",
        "df['texto_processado'] = df['descricao_reclamacao'].apply(norm_tokenize)\n",
        "\n",
        "# Separação dos dados\n",
        "X = df['texto_processado']\n",
        "y = df['categoria']\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Vetorização com TF-IDF (1-2)\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=5000)\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Modelo campeão: Regressão Logística\n",
        "modelo = LogisticRegression(max_iter=1000)\n",
        "modelo.fit(X_train_vec, y_train)\n",
        "\n",
        "# Avaliação com F1 Score\n",
        "y_pred = modelo.predict(X_test_vec)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "print(f'´ [ x ] F1 Score do modelo campeão (TF-IDF + Regressão Logística): {f1:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Conclusão**\n",
        "\n",
        "Este projeto atingiu com sucesso o objetivo de construir um classificador de assuntos para a QuantumFinance com F1 Score superior a 75%.\n",
        "\n",
        "- A abordagem com **TF-IDF + Regressão Logística** apresentou desempenho superior (~90%), sendo ideal para ambientes leves e rápidos.\n",
        "- O modelo BERT fine-tunado atingiu ~86% de F1, mostrando bom entendimento contextual, mesmo com menos dados.\n",
        "\n",
        "* Considerações finais:\n",
        "- Para produção, o modelo clássico pode ser preferido pela leveza.\n",
        "- Para maior robustez e interpretação semântica, o BERT fine-tunado é altamente promissor.\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
