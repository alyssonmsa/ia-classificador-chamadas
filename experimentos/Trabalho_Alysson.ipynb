{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QuantumFinance - Classificação de Assuntos com BERT (Parte 02)\n",
    "\n",
    "## 1. Setup Inicial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Etapa 1 de 10\n",
    "# Importa bibliotecas essenciais e define o dispositivo (GPU ou CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn import preprocessing\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Verifica o dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Executando em:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etapa auxiliar\n",
    "# Parâmetros ajustáveis para facilitar tuning posterior\n",
    "\n",
    "MAX_LENGTH = 256       # Tamanho máximo de tokens por entrada\n",
    "BATCH_SIZE = 32        # Tamanho do batch para treino\n",
    "LEARNING_RATE = 5e-5   # Taxa de aprendizado\n",
    "EPOCHS = 3             # Número de épocas de treinamento\n",
    "DEV_MODE = True        # Usa apenas uma amostra do dataset para acelerar testes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carregamento dos Dados\n",
    "\n",
    "```python\n",
    "# Etapa 2 de 10\n",
    "# Carrega o dataset CSV com separador ';' e explora as colunas principais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o dataset CSV com separador ';' e aplica modo de desenvolvimento (10%) se ativado\n",
    "\n",
    "caminho_arquivo = 'tickets_reclamacoes_classificados.csv'\n",
    "df = pd.read_csv(caminho_arquivo, sep=';')\n",
    "\n",
    "# Ativa modo de desenvolvimento com amostragem reduzida\n",
    "if DEV_MODE:\n",
    "    df = df.sample(frac=0.1, random_state=42).reset_index(drop=True)\n",
    "    print(f\"[MODO DEV ATIVADO] Usando {len(df)} amostras\")\n",
    "\n",
    "print(\"Amostra dos dados:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"Colunas disponíveis:\", df.columns.tolist())\n",
    "print(\"\\nDistribuição das categorias:\")\n",
    "print(df['categoria'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 3 de 10\n",
    "- Normaliza os textos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "institution_names = ['chase', 'bank', 'jp', 'gm', 'financial', 'jpmcb']\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(table)\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+|/', '', text)\n",
    "    text = re.sub(r'\\bx\\b|\\w*xx+\\w*', '', text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    for institution in institution_names:\n",
    "        text = re.sub(r'\\b' + re.escape(institution) + r'\\b', '[INST]', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Cria nova coluna com texto normalizado\n",
    "df['texto_limpo'] = df['descricao_reclamacao'].apply(normalize_text)\n",
    "\n",
    "# Visualiza resultado\n",
    "print(\"Pré-visualização das colunas originais e normalizadas:\")\n",
    "df[['descricao_reclamacao', 'texto_limpo']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tokenização com BERT\n",
    "```python\n",
    "# Etapa 4 de 10\n",
    "# Tokeniza os textos normalizados usando BERT e armazena input_ids e attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
    "\n",
    "# Tokenização e vetorização dos textos normalizados\n",
    "def tokenize_bert(text):\n",
    "    tokens = tokenizer(\n",
    "        text,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    return tokens\n",
    "\n",
    "# Aplica tokenização e extrai os tensores como listas\n",
    "encoded = df['texto_limpo'].apply(tokenize_bert)\n",
    "df['input_ids'] = encoded.apply(lambda x: x['input_ids'].squeeze().tolist())\n",
    "df['attention_mask'] = encoded.apply(lambda x: x['attention_mask'].squeeze().tolist())\n",
    "\n",
    "# Visualiza colunas com embeddings\n",
    "print(\"Pré-visualização dos textos tokenizados:\")\n",
    "df[['texto_limpo', 'input_ids', 'attention_mask']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Codificação dos Rótulos\n",
    "\n",
    "```python\n",
    "# Etapa 5 de 10\n",
    "# Codifica os rótulos da coluna 'categoria' em valores numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['categoria'])\n",
    "\n",
    "# Visualiza a correspondência\n",
    "print(\"Categorias codificadas:\")\n",
    "display(pd.DataFrame({\n",
    "    'categoria': label_encoder.classes_,\n",
    "    'label': list(range(len(label_encoder.classes_)))\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Tensores e Split Treino/Teste\n",
    "\n",
    "```python\n",
    "# Etapa 6 de 10\n",
    "# Cria os tensores (input_ids, attention_mask, label) e divide os dados (75/25 com random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte listas para tensores\n",
    "input_ids_tensor = torch.tensor(df['input_ids'].tolist())\n",
    "attention_mask_tensor = torch.tensor(df['attention_mask'].tolist())\n",
    "labels_tensor = torch.tensor(df['label'].tolist())\n",
    "\n",
    "# Realiza o split dos índices para manter os dados organizados\n",
    "train_idx, test_idx = train_test_split(\n",
    "    range(len(df)),\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=df['label']  # garante distribuição proporcional\n",
    ")\n",
    "\n",
    "# Cria conjuntos de treino e teste\n",
    "train_dataset = TensorDataset(\n",
    "    input_ids_tensor[train_idx],\n",
    "    attention_mask_tensor[train_idx],\n",
    "    labels_tensor[train_idx]\n",
    ")\n",
    "\n",
    "test_dataset = TensorDataset(\n",
    "    input_ids_tensor[test_idx],\n",
    "    attention_mask_tensor[test_idx],\n",
    "    labels_tensor[test_idx]\n",
    ")\n",
    "\n",
    "print(f\"Tamanho do treino: {len(train_dataset)}\")\n",
    "print(f\"Tamanho do teste: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificar o comprimento dos tokens para ajusta de parametros\n",
    "#df['comprimento_tokens'] = df['texto_limpo'].apply(lambda x: len(tokenizer.tokenize(x)))\n",
    "#df['comprimento_tokens'].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Construção e Treinamento do Modelo BERT\n",
    "\n",
    "```python\n",
    "# Etapa 7 de 10\n",
    "# Instancia o modelo BERT para classificação e realiza o treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(label_encoder.classes_)\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'neuralmind/bert-base-portuguese-cased',\n",
    "    num_labels=num_labels\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# Otimizador e parâmetros\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "batch_size = BATCH_SIZE\n",
    "epochs = EPOCHS\n",
    "\n",
    "# Loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Treinamento\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nÉpoca {epoch + 1}/{epochs}\")\n",
    "    for batch in tqdm(train_loader):\n",
    "        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Loss final da época {epoch + 1}: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Avaliação do Modelo\n",
    "\n",
    "```python\n",
    "# Etapa 8 de 10\n",
    "# Avalia o modelo no conjunto de teste usando F1 Score e classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in DataLoader(test_dataset, batch_size=BATCH_SIZE):\n",
    "        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Relatório de classificação\n",
    "print(classification_report(all_labels, all_preds, target_names=label_encoder.classes_))\n",
    "\n",
    "# F1 Score Macro\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "print(f\"F1 Score (macro): {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Salvamento do Modelo\n",
    "\n",
    "```python\n",
    "# Etapa 9 de 10\n",
    "# Salva o modelo treinado, o tokenizer e o codificador de rótulos (label encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Cria pasta se não existir\n",
    "import os\n",
    "os.makedirs(\"modelo_quantumfinance\", exist_ok=True)\n",
    "\n",
    "# Salva modelo e tokenizer\n",
    "model.save_pretrained(\"modelo_quantumfinance\")\n",
    "tokenizer.save_pretrained(\"modelo_quantumfinance\")\n",
    "\n",
    "# Salva o label encoder\n",
    "joblib.dump(label_encoder, \"modelo_quantumfinance/label_encoder.pkl\")\n",
    "\n",
    "print(\"Modelo, tokenizer e label encoder salvos em 'modelo_quantumfinance/'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Predição com Texto Novo\n",
    "\n",
    "```python\n",
    "# Etapa 10 de 10\n",
    "# Usa o modelo treinado para prever a categoria de um novo texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prever_texto(texto):\n",
    "    texto_limpo = normalize_text(texto)\n",
    "    tokens = tokenizer(texto_limpo, return_tensors='pt', truncation=True, padding='max_length', max_length=MAX_LENGTH)\n",
    "    tokens = {k: v.to(device) for k, v in tokens.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(**tokens)\n",
    "        pred = torch.argmax(output.logits, dim=1).cpu().item()\n",
    "\n",
    "    return label_encoder.inverse_transform([pred])[0]\n",
    "\n",
    "# Exemplo de uso:\n",
    "texto_exemplo = \"Gostaria de abrir um banco no brasil.\"\n",
    "print(\"Assunto previsto:\", prever_texto(texto_exemplo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casos_teste = {\n",
    "    \"caso_cartao_1\": \"Recebi uma cobrança indevida no meu cartão de crédito e não consigo cancelar.\",\n",
    "    \"caso_cartao_2\": \"Preciso desbloquear meu cartão pré-pago que foi bloqueado sem explicação.\",\n",
    "    \"caso_emprestimo\": \"Estou com problemas para renegociar meu empréstimo estudantil.\",\n",
    "    \"caso_hipoteca\": \"O banco está me cobrando taxas abusivas na minha hipoteca.\",\n",
    "    \"caso_conta\": \"Minha conta foi encerrada sem aviso e perdi o acesso ao meu saldo.\",\n",
    "    \"caso_roubo_1\": \"Alguém fez compras no meu nome, quero reportar uma fraude.\",\n",
    "    \"caso_roubo_2\": \"Tem transações estranhas no meu extrato, acho que fui vítima de golpe.\",\n",
    "    \"caso_outros_1\": \"Quero atualizar meu endereço de correspondência.\",\n",
    "    \"caso_outros_2\": \"Estou tentando mudar minha senha, mas o sistema não deixa.\",\n",
    "}\n",
    "\n",
    "for nome, texto in casos_teste.items():\n",
    "    categoria = prever_texto(texto)\n",
    "    print(f\"{nome}: {categoria}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
